{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAlDv-TC_cxX",
        "outputId": "7f870654-840a-41ed-e16c-1022fe0a2ebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'fed-conv-social-pooling'...\n",
            "remote: Enumerating objects: 52, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 52 (delta 0), reused 0 (delta 0), pack-reused 49 (from 1)\u001b[K\n",
            "Receiving objects: 100% (52/52), 26.95 KiB | 452.00 KiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/takakib123/fed-conv-social-pooling.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJbEeZIn_mw6"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/Datasets/ngsim dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX9bbxlJ_tG6",
        "outputId": "ce23df4b-affd-426b-d022-ecab391903cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/fed-conv-social-pooling\n"
          ]
        }
      ],
      "source": [
        "%cd /content/fed-conv-social-pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGmkSJ-fHDfq",
        "outputId": "73828e96-ddf4-4d28-d440-df52bd67a1e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Create a new API key at: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Store your API key securely and do not share it.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste your API key and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makibc123\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gNb-XWJ5_2Zr",
        "outputId": "6aa74d15-6262-4faa-866c-80b31bb68efa"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to True."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>client_0/train_loss</td><td>█▄▃▁▃</td></tr><tr><td>client_id</td><td>▁▁▁▁▁</td></tr><tr><td>global_step</td><td>▁▃▅▆█</td></tr><tr><td>local_step</td><td>▁▃▅▆█</td></tr><tr><td>round</td><td>▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>client_0/train_loss</td><td>359.15649</td></tr><tr><td>client_id</td><td>0</td></tr><tr><td>global_step</td><td>50</td></tr><tr><td>local_step</td><td>49</td></tr><tr><td>round</td><td>1</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">smart-serenity-24</strong> at: <a href='https://wandb.ai/akibc123/conv-social-pooling-fl/runs/eg0616vh' target=\"_blank\">https://wandb.ai/akibc123/conv-social-pooling-fl/runs/eg0616vh</a><br> View project at: <a href='https://wandb.ai/akibc123/conv-social-pooling-fl' target=\"_blank\">https://wandb.ai/akibc123/conv-social-pooling-fl</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20260216_003853-eg0616vh/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.24.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/fed-conv-social-pooling/wandb/run-20260216_004152-4lz3ckr9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/akibc123/conv-social-pooling-fl/runs/4lz3ckr9' target=\"_blank\">jolly-blaze-25</a></strong> to <a href='https://wandb.ai/akibc123/conv-social-pooling-fl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/akibc123/conv-social-pooling-fl' target=\"_blank\">https://wandb.ai/akibc123/conv-social-pooling-fl</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/akibc123/conv-social-pooling-fl/runs/4lz3ckr9' target=\"_blank\">https://wandb.ai/akibc123/conv-social-pooling-fl/runs/4lz3ckr9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded successfully.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>client_0/train_loss</td><td>█▄▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>client_1/train_loss</td><td>█▃▂▂▂▂▄▂▄▂▁▂▁▁</td></tr><tr><td>client_2/train_loss</td><td>▇▅▅▂▂█▂▂▁▁▃▄▂▁</td></tr><tr><td>client_3/train_loss</td><td>▅▂▃█▅▃▁▁▂▂▁▁▂▁</td></tr><tr><td>client_4/train_loss</td><td>█▄▃▅▆▃▃▂▂▂▃▄▁▂</td></tr><tr><td>client_5/train_loss</td><td>█▅▄▃▂▂▃▂▂▃▁▁▂▁</td></tr><tr><td>client_6/train_loss</td><td>█▃▃▂▅▂▂▂▂▂▁▂▂▂</td></tr><tr><td>client_7/train_loss</td><td>█▃▂▁▁▂▁▁▂▂▂▁▂▂</td></tr><tr><td>client_8/train_loss</td><td>█▂▂▁▂▂▂▁▂▁▁▂▁▁</td></tr><tr><td>client_9/train_loss</td><td>█▄▃▄▆▄▃▂▂▂▃▁▂▄</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>client_0/train_loss</td><td>271.42709</td></tr><tr><td>client_1/train_loss</td><td>86.61971</td></tr><tr><td>client_2/train_loss</td><td>62.09343</td></tr><tr><td>client_3/train_loss</td><td>66.58579</td></tr><tr><td>client_4/train_loss</td><td>79.26852</td></tr><tr><td>client_5/train_loss</td><td>133.60329</td></tr><tr><td>client_6/train_loss</td><td>88.17913</td></tr><tr><td>client_7/train_loss</td><td>61.65257</td></tr><tr><td>client_8/train_loss</td><td>56.85877</td></tr><tr><td>client_9/train_loss</td><td>42.66939</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">jolly-blaze-25</strong> at: <a href='https://wandb.ai/akibc123/conv-social-pooling-fl/runs/4lz3ckr9' target=\"_blank\">https://wandb.ai/akibc123/conv-social-pooling-fl/runs/4lz3ckr9</a><br> View project at: <a href='https://wandb.ai/akibc123/conv-social-pooling-fl' target=\"_blank\">https://wandb.ai/akibc123/conv-social-pooling-fl</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20260216_004152-4lz3ckr9/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import copy\n",
        "import logging\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "import wandb\n",
        "import gc\n",
        "# Import necessary modules from the provided file structure\n",
        "from model import highwayNet\n",
        "from utils import ngsimDataset, maskedNLL, maskedMSE, maskedNLLTest\n",
        "\n",
        "# --- Configuration & Logging Setup ---\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - [FL-System] - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"fl_experiment.log\", mode='w'),\n",
        "        logging.StreamHandler(sys.stdout)\n",
        "    ]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "ARGS = {\n",
        "    'use_cuda': True and torch.cuda.is_available(),\n",
        "    'encoder_size': 64,\n",
        "    'decoder_size': 128,\n",
        "    'in_length': 16,\n",
        "    'out_length': 25,\n",
        "    'grid_size': (13, 3),\n",
        "    'soc_conv_depth': 64,\n",
        "    'conv_3x1_depth': 16,\n",
        "    'dyn_embedding_size': 32,\n",
        "    'input_embedding_size': 32,\n",
        "    'num_lat_classes': 3,\n",
        "    'num_lon_classes': 2,\n",
        "    'use_maneuvers': True,\n",
        "    'train_flag': True,\n",
        "}\n",
        "\n",
        "# FL Hyperparameters\n",
        "NUM_CLIENTS = 10\n",
        "GLOBAL_ROUNDS = 8\n",
        "LOCAL_EPOCHS = 2\n",
        "PRETRAIN_ROUNDS = 3\n",
        "BATCH_SIZE = 8192\n",
        "DEVICE = torch.device(\"cuda\" if ARGS['use_cuda'] else \"cpu\")\n",
        "LOG_INTERVAL = 10\n",
        "REUSE_WEIGHTS = True\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "class FLClient:\n",
        "    def __init__(self, client_id, dataset, device, args):\n",
        "        self.client_id = client_id\n",
        "        self.dataset = dataset\n",
        "        self.device = device\n",
        "        self.args = args\n",
        "        self.net = highwayNet(args).to(device)\n",
        "        self.optimizer = torch.optim.Adam(self.net.parameters())\n",
        "        self.crossEnt = torch.nn.BCELoss()\n",
        "        self.dataloader = DataLoader(\n",
        "            self.dataset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            collate_fn=self.dataset.dataset.collate_fn\n",
        "        )\n",
        "\n",
        "    def train(self, global_weights, round_num, global_step_offset):\n",
        "        \"\"\"\n",
        "        Returns: (state_dict, avg_loss, steps_taken)\n",
        "        \"\"\"\n",
        "        self.net.load_state_dict(global_weights)\n",
        "        self.net.train()\n",
        "        self.net.train_flag = True\n",
        "\n",
        "        epoch_loss = 0\n",
        "        batch_count = 0\n",
        "        local_step = 0\n",
        "\n",
        "        use_mse_loss = round_num < PRETRAIN_ROUNDS\n",
        "        loss_mode = \"MSE\" if use_mse_loss else \"NLL\"\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(LOCAL_EPOCHS):\n",
        "            for i, data in enumerate(self.dataloader):\n",
        "                hist, nbrs, mask, lat_enc, lon_enc, fut, op_mask = data\n",
        "\n",
        "                if self.args['use_cuda']:\n",
        "                    hist = hist.to(self.device)\n",
        "                    nbrs = nbrs.to(self.device)\n",
        "                    mask = mask.to(self.device)\n",
        "                    lat_enc = lat_enc.to(self.device)\n",
        "                    lon_enc = lon_enc.to(self.device)\n",
        "                    fut = fut.to(self.device)\n",
        "                    op_mask = op_mask.to(self.device)\n",
        "\n",
        "                if self.args['use_maneuvers']:\n",
        "                    fut_pred, lat_pred, lon_pred = self.net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "                    if use_mse_loss:\n",
        "                        l = maskedMSE(fut_pred, fut, op_mask)\n",
        "                    else:\n",
        "                        l = maskedNLL(fut_pred, fut, op_mask) + \\\n",
        "                            self.crossEnt(lat_pred, lat_enc) + \\\n",
        "                            self.crossEnt(lon_pred, lon_enc)\n",
        "                else:\n",
        "                    fut_pred = self.net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "                    if use_mse_loss:\n",
        "                        l = maskedMSE(fut_pred, fut, op_mask)\n",
        "                    else:\n",
        "                        l = maskedNLL(fut_pred, fut, op_mask)\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                l.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.net.parameters(), 10)\n",
        "                self.optimizer.step()\n",
        "\n",
        "                epoch_loss += l.item()\n",
        "                batch_count += 1\n",
        "                local_step += 1\n",
        "\n",
        "\n",
        "                current_global_step = global_step_offset + local_step\n",
        "\n",
        "                if (i + 1) % LOG_INTERVAL == 0:\n",
        "                    log_msg = (f\"Client {self.client_id} | Round {round_num+1} | \"\n",
        "                               f\"Batch {i+1} | Loss ({loss_mode}): {l.item():.4f}\")\n",
        "                    logger.info(log_msg)\n",
        "\n",
        "                    # WandB: Log specific client metric, commit=True to push update immediately\n",
        "                    wandb.log({\n",
        "                        f\"client_{self.client_id}/train_loss\": l.item(),\n",
        "                        \"round\": round_num + 1,\n",
        "                        \"client_id\": self.client_id,\n",
        "                        \"global_step\": current_global_step,\n",
        "                        \"local_step\": round_num*batch_count + i,\n",
        "\n",
        "                    })\n",
        "\n",
        "\n",
        "        avg_loss = epoch_loss / batch_count if batch_count > 0 else 0\n",
        "\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        return self.net.state_dict(), avg_loss, local_step\n",
        "\n",
        "def fed_avg(weights_list):\n",
        "    w_avg = copy.deepcopy(weights_list[0])\n",
        "    for k in w_avg.keys():\n",
        "        for i in range(1, len(weights_list)):\n",
        "            w_avg[k] += weights_list[i][k]\n",
        "        w_avg[k] = torch.div(w_avg[k], len(weights_list))\n",
        "    return w_avg\n",
        "\n",
        "def validate_global_model(model, val_loader, round_num):\n",
        "    model.eval()\n",
        "    model.train_flag = False\n",
        "    avg_val_loss = 0\n",
        "    val_batch_count = 0\n",
        "    use_mse_loss = round_num < PRETRAIN_ROUNDS\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            hist, nbrs, mask, lat_enc, lon_enc, fut, op_mask = data\n",
        "            if ARGS['use_cuda']:\n",
        "                hist = hist.to(DEVICE)\n",
        "                nbrs = nbrs.to(DEVICE)\n",
        "                mask = mask.to(DEVICE)\n",
        "                lat_enc = lat_enc.to(DEVICE)\n",
        "                lon_enc = lon_enc.to(DEVICE)\n",
        "                fut = fut.to(DEVICE)\n",
        "                op_mask = op_mask.to(DEVICE)\n",
        "\n",
        "            if ARGS['use_maneuvers']:\n",
        "                if use_mse_loss:\n",
        "                    model.train_flag = True\n",
        "                    fut_pred, _, _ = model(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "                    l = maskedMSE(fut_pred, fut, op_mask)\n",
        "                    model.train_flag = False\n",
        "                else:\n",
        "                    fut_pred, lat_pred, lon_pred = model(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "                    l = maskedNLLTest(fut_pred, lat_pred, lon_pred, fut, op_mask, avg_along_time=True)\n",
        "            else:\n",
        "                fut_pred = model(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "                if use_mse_loss:\n",
        "                    l = maskedMSE(fut_pred, fut, op_mask)\n",
        "                else:\n",
        "                    l = maskedNLL(fut_pred, fut, op_mask)\n",
        "\n",
        "            avg_val_loss += l.item()\n",
        "            val_batch_count += 1\n",
        "\n",
        "    return avg_val_loss / val_batch_count if val_batch_count > 0 else 0\n",
        "\n",
        "def main():\n",
        "    # Force reinit to prevent Zombie processes from locking the run\n",
        "    wandb.init(\n",
        "        project=\"conv-social-pooling-fl\",\n",
        "        reinit=True,\n",
        "        config={\n",
        "            \"num_clients\": NUM_CLIENTS,\n",
        "            \"global_rounds\": GLOBAL_ROUNDS,\n",
        "            \"batch_size\": BATCH_SIZE\n",
        "        }\n",
        "    )\n",
        "\n",
        "    logger.info(\"Initializing Federated Learning Pipeline...\")\n",
        "\n",
        "    train_dataset = ngsimDataset('data/TrainSet.mat')\n",
        "    val_dataset_full = ngsimDataset('data/ValSet.mat')\n",
        "\n",
        "    val_len = len(val_dataset_full)\n",
        "    VAL_SUBSET_RATIO = 1\n",
        "    short_val_len = int(val_len * VAL_SUBSET_RATIO)\n",
        "    logger.info(f\"Shortening validation set: {short_val_len} samples (Original: {val_len})\")\n",
        "\n",
        "    val_subset = Subset(val_dataset_full, list(range(short_val_len)))\n",
        "\n",
        "\n",
        "    val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False,\n",
        "                           num_workers=0, collate_fn=val_dataset_full.collate_fn)\n",
        "\n",
        "    # Partition Data\n",
        "    total_samples = int(len(train_dataset)/1)\n",
        "    indices = list(range(total_samples))\n",
        "    split_size = total_samples // NUM_CLIENTS\n",
        "\n",
        "    clients = []\n",
        "    for i in range(NUM_CLIENTS):\n",
        "        idx_start = i * split_size\n",
        "        idx_end = (i + 1) * split_size\n",
        "        client_subset = Subset(train_dataset, indices[idx_start:idx_end])\n",
        "        clients.append(FLClient(i, client_subset, DEVICE, ARGS))\n",
        "\n",
        "    global_model = highwayNet(ARGS).to(DEVICE)\n",
        "\n",
        "\n",
        "    if REUSE_WEIGHTS:\n",
        "        checkpoint_path = '/content/drive/MyDrive/Fed_traf/fed/fl_global_round_2.tar' # Or your best model\n",
        "        # Handle cases where checkpoint saves 'state_dict' key or just weights\n",
        "        state = torch.load(checkpoint_path, map_location=DEVICE)\n",
        "        if 'state_dict' in state:\n",
        "            global_model = net.load_state_dict(state['state_dict'])\n",
        "        else:\n",
        "            global_model.load_state_dict(state)\n",
        "        print(\"Model loaded successfully.\")\n",
        "\n",
        "    global_weights = global_model.state_dict()\n",
        "\n",
        "    if not os.path.exists('trained_models'):\n",
        "        os.makedirs('trained_models')\n",
        "\n",
        "    # Variable to track X-axis alignment across rounds\n",
        "    global_step_tracker = 0\n",
        "\n",
        "    for round_num in range(GLOBAL_ROUNDS):\n",
        "        logger.info(f\"--- Global Round {round_num + 1}/{GLOBAL_ROUNDS} ---\")\n",
        "\n",
        "        local_weights_list = []\n",
        "        local_losses = []\n",
        "\n",
        "        # Track max steps in this round to sync global_step_tracker\n",
        "        max_steps_in_round = 0\n",
        "\n",
        "        for client in clients:\n",
        "            # Pass the current global step offset to the client\n",
        "            w_local, loss, steps_taken = client.train(global_weights, round_num, global_step_tracker)\n",
        "            local_weights_list.append(w_local)\n",
        "            local_losses.append(loss)\n",
        "\n",
        "            # We assume clients run in parallel (conceptually), so they share the same X-axis range.\n",
        "            # We just need to know how much to advance the tracker for the NEXT round.\n",
        "            if steps_taken > max_steps_in_round:\n",
        "                max_steps_in_round = steps_taken\n",
        "\n",
        "        # Advance the global step tracker by the length of one client's epoch\n",
        "        global_step_tracker += max_steps_in_round\n",
        "\n",
        "        # Aggregation\n",
        "        global_weights = fed_avg(local_weights_list)\n",
        "        global_model.load_state_dict(global_weights)\n",
        "\n",
        "        # Validation\n",
        "        val_loss = validate_global_model(global_model, val_loader, round_num)\n",
        "\n",
        "        avg_train_loss = sum(local_losses) / len(local_losses)\n",
        "        loss_mode = \"MSE\" if round_num < PRETRAIN_ROUNDS else \"NLL\"\n",
        "\n",
        "        logger.info(f\"Round {round_num + 1} | Val Loss: {val_loss:.4f} [{loss_mode}]\")\n",
        "\n",
        "        # Log Global Metrics\n",
        "        wandb.log({\n",
        "            \"global/val_loss\": val_loss,\n",
        "            \"global/avg_train_loss\": avg_train_loss,\n",
        "            \"round\": round_num + 1,\n",
        "            \"global_step\": global_step_tracker\n",
        "        })\n",
        "\n",
        "\n",
        "        torch.save(global_weights, f'trained_models/fl_global_round_{round_num+1}.tar')\n",
        "\n",
        "    logger.info(\"Federated Learning Complete.\")\n",
        "    wandb.finish()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdodD1WvAeEI",
        "outputId": "98a61b84-34fe-4b1f-afbc-22a601511656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model (expecting out_length=25)...\n",
            "Model loaded successfully.\n",
            "Loading test data from /content/fed-conv-social-pooling/data/TestSet_Keep.mat...\n",
            "Running evaluation...\n",
            "\n",
            "=================================================================\n",
            "EVALUATION RESULTS (All Metrics in Meters)\n",
            "=================================================================\n",
            "Metric       | 1.0s     | 2.0s     | 3.0s     | 4.0s     | 5.0s    \n",
            "-------------------------------------------------------------------\n",
            "RMSE         | 0.590    | 1.269    | 2.100    | 3.152    | 4.460   \n",
            "ADE          | 0.228    | 0.464    | 0.729    | 1.035    | 1.392   \n",
            "FDE          | 0.404    | 0.912    | 1.528    | 2.305    | 3.273   \n",
            "=================================================================\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "import numpy as np\n",
        "import math\n",
        "from model import highwayNet\n",
        "from utils import ngsimDataset, maskedMSETest\n",
        "\n",
        "def main():\n",
        "    # --- 1. Configuration ---\n",
        "    args = {}\n",
        "    args['use_cuda'] = torch.cuda.is_available()\n",
        "    args['encoder_size'] = 64\n",
        "    args['decoder_size'] = 128\n",
        "    args['in_length'] = 16\n",
        "\n",
        "    # Check if you want to evaluate 2.5s (25) or 5s (50)\n",
        "    args['out_length'] = 25\n",
        "\n",
        "    args['grid_size'] = (13,3)\n",
        "    args['soc_conv_depth'] = 64\n",
        "    args['conv_3x1_depth'] = 16\n",
        "    args['dyn_embedding_size'] = 32\n",
        "    args['input_embedding_size'] = 32\n",
        "    args['num_lat_classes'] = 3\n",
        "    args['num_lon_classes'] = 2\n",
        "    args['use_maneuvers'] = True\n",
        "    args['train_flag'] = False\n",
        "\n",
        "    device = torch.device(\"cuda\" if args['use_cuda'] else \"cpu\")\n",
        "\n",
        "    # --- 2. Load Model ---\n",
        "    print(f\"Loading model (expecting out_length={args['out_length']})...\")\n",
        "    net = highwayNet(args).to(device)\n",
        "\n",
        "    try:\n",
        "        checkpoint_path = '/content/drive/MyDrive/Fed_traf/central/trained_models/cslstm_central_final.tar'\n",
        "        state = torch.load(checkpoint_path, map_location=device)\n",
        "        if 'state_dict' in state:\n",
        "            net.load_state_dict(state['state_dict'])\n",
        "        else:\n",
        "            net.load_state_dict(state)\n",
        "        print(\"Model loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    # --- 3. Load Test Data ---\n",
        "    dataset_path = '/content/fed-conv-social-pooling/data/TestSet_Keep.mat'\n",
        "    print(f\"Loading test data from {dataset_path}...\")\n",
        "\n",
        "    tsSet_full = ngsimDataset(dataset_path)\n",
        "    len_tes = int(len(tsSet_full)/1)\n",
        "    tsSet = Subset(tsSet_full, list(range(len_tes)))\n",
        "    tsDataloader = DataLoader(tsSet, batch_size=128, shuffle=False, num_workers=8, collate_fn=tsSet_full.collate_fn)\n",
        "\n",
        "    # --- 4. Evaluation Loop ---\n",
        "\n",
        "    # Trackers for RMSE (Squared Error)\n",
        "    lossVals = torch.zeros(args['out_length']).to(device)\n",
        "    counts = torch.zeros(args['out_length']).to(device)\n",
        "\n",
        "    # Trackers for ADE/FDE (L2 Distance at every time step)\n",
        "    fdeVals = torch.zeros(args['out_length']).to(device)\n",
        "    fdeCounts = torch.zeros(args['out_length']).to(device)\n",
        "\n",
        "    print(\"Running evaluation...\")\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(tsDataloader):\n",
        "            hist, nbrs, mask, lat_enc, lon_enc, fut, op_mask = data\n",
        "\n",
        "            if args['use_cuda']:\n",
        "                hist = hist.to(device)\n",
        "                nbrs = nbrs.to(device)\n",
        "                mask = mask.to(device)\n",
        "                lat_enc = lat_enc.to(device)\n",
        "                lon_enc = lon_enc.to(device)\n",
        "                fut = fut.to(device)\n",
        "                op_mask = op_mask.to(device)\n",
        "\n",
        "            # --- Forward Pass ---\n",
        "            if args['use_maneuvers']:\n",
        "                fut_pred, lat_pred, lon_pred = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "\n",
        "                fut_pred_max = torch.zeros_like(fut_pred[0])\n",
        "                for k in range(lat_pred.shape[0]):\n",
        "                    lat_man = torch.argmax(lat_pred[k, :]).detach()\n",
        "                    lon_man = torch.argmax(lon_pred[k, :]).detach()\n",
        "                    indx = lon_man*3 + lat_man\n",
        "                    fut_pred_max[:,k,:] = fut_pred[indx][:,k,:]\n",
        "\n",
        "                pred_to_eval = fut_pred_max\n",
        "            else:\n",
        "                fut_pred = net(hist, nbrs, mask, lat_enc, lon_enc)\n",
        "                pred_to_eval = fut_pred\n",
        "\n",
        "            # --- 1. RMSE Accumulation ---\n",
        "            l, c = maskedMSETest(pred_to_eval, fut, op_mask)\n",
        "            time_steps = l.shape[0]\n",
        "            lossVals[:time_steps] += l.detach()\n",
        "            counts[:time_steps] += c.detach()\n",
        "\n",
        "            # --- 2. ADE/FDE Accumulation (Per Time-Step) ---\n",
        "            # Extract only muX, muY\n",
        "            pred_pos = pred_to_eval[:, :, 0:2]\n",
        "\n",
        "            # L2 norm (Euclidean distance) in feet\n",
        "            diff = pred_pos - fut\n",
        "            dist_l2 = torch.norm(diff, dim=2) # [Seq_Len, Batch]\n",
        "\n",
        "            valid_mask = op_mask[:, :, 0] # [Seq_Len, Batch]\n",
        "            masked_dist = dist_l2 * valid_mask\n",
        "\n",
        "            # Sum the L2 distances across the batch FOR EACH time step\n",
        "            fdeVals[:time_steps] += torch.sum(masked_dist, dim=1).detach()\n",
        "            fdeCounts[:time_steps] += torch.sum(valid_mask, dim=1).detach()\n",
        "\n",
        "\n",
        "    # --- 5. Formatting Results ---\n",
        "\n",
        "    # 1. RMSE at each time step\n",
        "    rmse_meters = torch.pow(lossVals / counts, 0.5) * 0.3048\n",
        "    rmse_meters = rmse_meters.cpu().numpy()\n",
        "\n",
        "    # 2. FDE exactly at each time step\n",
        "    fde_meters = (fdeVals / fdeCounts) * 0.3048\n",
        "    fde_meters = fde_meters.cpu().numpy()\n",
        "\n",
        "    # 3. ADE up to each time step (Cumulative Average)\n",
        "    cum_fdeVals = torch.cumsum(fdeVals, dim=0)\n",
        "    cum_fdeCounts = torch.cumsum(fdeCounts, dim=0)\n",
        "    ade_meters = (cum_fdeVals / cum_fdeCounts) * 0.3048\n",
        "    ade_meters = ade_meters.cpu().numpy()\n",
        "\n",
        "    # --- Print Unified Table ---\n",
        "    print(\"\\n\" + \"=\"*65)\n",
        "    print(\"EVALUATION RESULTS (All Metrics in Meters)\")\n",
        "    print(\"=\"*65)\n",
        "\n",
        "    horizons = [5, 10, 15, 20, 25]\n",
        "\n",
        "    headers = []\n",
        "    rmse_out = []\n",
        "    ade_out = []\n",
        "    fde_out = []\n",
        "\n",
        "    for h in horizons:\n",
        "        idx = h - 1 # 0-indexed tensor\n",
        "        if idx < len(rmse_meters):\n",
        "            time_label = f\"{h/5:.1f}s\"\n",
        "            headers.append(time_label)\n",
        "\n",
        "            rmse_out.append(f\"{rmse_meters[idx]:.3f}\")\n",
        "            ade_out.append(f\"{ade_meters[idx]:.3f}\")\n",
        "            fde_out.append(f\"{fde_meters[idx]:.3f}\")\n",
        "\n",
        "    # Build and align the table\n",
        "    print(f\"{'Metric':<12} | \" + \" | \".join([f\"{h:<8}\" for h in headers]))\n",
        "    print(\"-\" * (12 + 11 * len(headers)))\n",
        "    print(f\"{'RMSE':<12} | \" + \" | \".join([f\"{v:<8}\" for v in rmse_out]))\n",
        "    print(f\"{'ADE':<12} | \" + \" | \".join([f\"{v:<8}\" for v in ade_out]))\n",
        "    print(f\"{'FDE':<12} | \" + \" | \".join([f\"{v:<8}\" for v in fde_out]))\n",
        "    print(\"=\"*65)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
